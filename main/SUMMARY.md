# Legal RAG System - Complete Summary

Tá»•ng quan há»‡ thá»‘ng RAG hoÃ n chá»‰nh cho tÆ° váº¥n phÃ¡p luáº­t Viá»‡t Nam.

---

## ğŸ—ï¸ **System Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER QUERY                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUERY PROCESSING (LLM-based)                                â”‚
â”‚  â”œâ”€ Normalization: Fix typos, standardize terminology        â”‚
â”‚  â””â”€ Classification: Legal vs Non-legal                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚
        â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NON-LEGAL  â”‚    â”‚     LEGAL       â”‚
â”‚   Direct    â”‚    â”‚   RAG Pipeline  â”‚
â”‚  Generate   â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   RETRIEVAL     â”‚
                   â”‚  (Multi-stage)  â”‚
                   â”‚  â”œâ”€ Embedding   â”‚
                   â”‚  â””â”€ Reranking   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ CONTEXT ASSEMBLYâ”‚
                   â”‚  (Reassemble)   â”‚
                   â”‚  â”œâ”€ Detect splitâ”‚
                   â”‚  â”œâ”€ Fetch parts â”‚
                   â”‚  â””â”€ Merge full  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   GENERATION    â”‚
                   â”‚   (LLM + ctx)   â”‚
                   â”‚  â”œâ”€ Reasoning   â”‚
                   â”‚  â””â”€ Citations   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ POST-PROCESSING â”‚
                   â”‚  â”œâ”€ Format      â”‚
                   â”‚  â”œâ”€ Confidence  â”‚
                   â”‚  â””â”€ Citations   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    ANSWER    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ **Components**

### **1. RAGchunking.py**
- **Purpose**: Context-aware chunking
- **Strategy**: Clause-based (má»—i khoáº£n = 1 chunk)
- **Features**:
  - Token-aware splitting (max 180 tokens)
  - Parent-child linking
  - Context preservation
- **Output**: 1,474 chunks (86.3% complete, 13.7% split)

### **2. RAGembedding.py**
- **Purpose**: Vector embedding
- **Model**: huyydangg/DEk21_hcmute_embedding
- **Features**:
  - 768-dimensional vectors
  - Vietnamese optimization
  - Persistent storage (4.32 MB)
- **Output**: context_aware_vectors.pkl

### **3. RAGretrieval.py**
- **Purpose**: Advanced retrieval
- **Strategy**: Dual scoring (40% embedding + 60% rerank)
- **Features**:
  - Multi-stage retrieval
  - Rerank model: hghaan/rerank_model
  - 8-bit quantization (50% RAM reduction)
  - Confidence scoring
- **Output**: Top-K chunks with scores

### **4. RAGassistant.py** (NEW!)
- **Purpose**: Complete RAG orchestrator
- **LLM**: Qwen3 1.7B Legal GRPO Phase 2
- **Features**:
  - Query normalization (LLM-based)
  - Query classification (2 labels)
  - Context assembly (full reassembly)
  - Answer generation
  - Interactive CLI
- **Output**: Complete legal answers

---

## ğŸ¯ **Key Features**

### **1. Query Processing**
```python
# Normalization
"hinh phat tu hinh" â†’ "hÃ¬nh pháº¡t tá»­ hÃ¬nh"
"700 trieu" â†’ "700.000.000 Ä‘á»“ng"

# Classification
"Äiá»u 40 quy Ä‘á»‹nh gÃ¬?" â†’ legal
"Thá»i tiáº¿t hÃ´m nay?" â†’ non-legal
```

### **2. Context Assembly** (NEW!)
```python
# Before
Ä‘iá»u_3_khoan_1_part_0 â†’ [INCOMPLETE]

# After
Ä‘iá»u_3_khoan_1_part_0 + part_1 â†’ [COMPLETE 100%]
```

### **3. Dual Scoring**
```python
combined_score = 0.4 * embedding_score + 0.6 * rerank_score
```

### **4. Confidence Metrics**
```python
ğŸŸ¢ Cao (â‰¥70%)
ğŸŸ¡ Trung bÃ¬nh (60-70%)
ğŸ”´ Tháº¥p (<60%)
```

---

## ğŸ“Š **Performance**

### **Chunking**
- Total: 1,474 chunks
- Complete: 1,272 (86.3%)
- Split: 202 (13.7%)
- Families: 76

### **Embedding**
- Model size: 768D
- Vector store: 4.32 MB
- Search speed: ~100ms

### **Retrieval**
- Initial candidates: 15
- Final results: 5
- Rerank time: ~2-3s

### **Generation**
- LLM size: 3.44 GB (1.7B params)
- Generation time: ~3-5s
- Total pipeline: ~6-9s

### **Memory Usage**
- Standard: ~4.7 GB
- With 8-bit: ~2.3 GB (50% reduction)
- With 4-bit: ~1.2 GB (75% reduction)

---

## ğŸš€ **Usage**

### **Quick Start**
```bash
# Setup
cd main
pip install -r ../requirements_rag.txt

# Run
python RAGassistant.py
```

### **Interactive Session**
```
â“ CÃ¢u há»i cá»§a báº¡n: hÃ¬nh pháº¡t tá»­ hÃ¬nh Ã¡p dá»¥ng nhÆ° tháº¿ nÃ o

ğŸ” Processing query...
   ğŸ“ Normalizing...
   ğŸ·ï¸  Classifying: legal
   ğŸ” Retrieving: 5 chunks
   ğŸ”— Assembling: 2 split chunks
   ğŸ¤– Generating answer...

âš–ï¸  Tráº£ lá»i:
[Detailed legal answer with citations]

ğŸ“– CÄƒn cá»© phÃ¡p lÃ½:
â€¢ Äiá»u 40. Tá»­ hÃ¬nh
â€¢ Äiá»u 12. Tuá»•i chá»‹u trÃ¡ch nhiá»‡m hÃ¬nh sá»±

ğŸ“Š Äá»™ tin cáº­y: Cao (85%)
```

---

## ğŸ“š **Documentation**

### **Core Docs**
- `README_chunking.md` - Chunking strategy
- `README_embedding.md` - Embedding system
- `README_retrieval.md` - Retrieval system
- `README_assistant.md` - Complete RAG system

### **Advanced Docs**
- `README_context_assembly.md` - Context assembly feature
- `README_optimization.md` - Memory optimization

### **Test Scripts**
- `test_context_assembly.py` - Test context assembly

---

## ğŸ”§ **Configuration**

### **Retrieval Config**
```python
RetrievalConfig(
    embedding_weight=0.4,
    reranker_weight=0.6,
    initial_search_k=15,
    final_results_k=5
)
```

### **Generation Config**
```python
# Normalization
temperature=0.1, max_tokens=256

# Classification  
temperature=0.1, max_tokens=32

# Legal Generation
temperature=0.2, max_tokens=1024
```

### **Optimization Config**
```python
# 8-bit quantization
load_in_8bit=True  # 50% RAM reduction

# 4-bit quantization
load_in_4bit=True  # 75% RAM reduction
```

---

## ğŸ“ **Best Practices**

### **1. Query Formulation**
- âœ… Be specific about legal concepts
- âœ… Use proper legal terminology
- âœ… Mention article numbers if known

### **2. Result Interpretation**
- âœ… Check confidence scores
- âœ… Review citations
- âœ… Verify with legal professionals

### **3. System Optimization**
- âœ… Use 8-bit quantization for balance
- âœ… Monitor RAM usage
- âœ… Adjust top-K based on needs

---

## âš ï¸ **Limitations**

### **1. Domain Specific**
- Only for Vietnamese criminal law
- Based on Bá»™ luáº­t HÃ¬nh sá»± 100/2015/QH13
- Not for other legal domains

### **2. Not Legal Advice**
- For educational/research purposes
- Preliminary guidance only
- Always consult legal professionals

### **3. Model Limitations**
- LLM: 1.7B params (not GPT-4 level)
- Context: 8192 tokens max
- May miss complex reasoning

---

## ğŸ”„ **Workflow**

### **Development Workflow**
```bash
1. Prepare data â†’ data/01_VBHN-VPQH_363655.txt
2. Run chunking â†’ python RAGchunking.py
3. Create embeddings â†’ python RAGembedding.py
4. Test retrieval â†’ python RAGretrieval.py
5. Run assistant â†’ python RAGassistant.py
```

### **Production Workflow**
```bash
1. Load pre-built vectors
2. Initialize assistant
3. Serve queries
4. Monitor performance
5. Update as needed
```

---

## ğŸ“ˆ **Future Improvements**

### **Planned Features**
1. **Multi-document support**: Beyond criminal law
2. **Conversation memory**: Track multi-turn dialogues
3. **Hybrid search**: Add keyword search
4. **Fine-tuning**: Custom legal LLM
5. **Web interface**: User-friendly UI
6. **API service**: REST API endpoints

### **Optimization Opportunities**
1. **ONNX Runtime**: 2-3x faster inference
2. **Caching**: Cache common queries
3. **Parallel processing**: Batch queries
4. **Model distillation**: Smaller models

---

## ğŸ™ **Acknowledgments**

- **Qwen Team**: Base LLM model
- **HuggingFace**: Transformers library
- **TRL Team**: GRPO implementation
- **Model Authors**: Vietnamese legal models

---

## ğŸ“ **Support**

### **Issues**
- Check documentation first
- Review error messages
- Test with simple queries

### **Contributing**
- Report bugs
- Suggest features
- Submit improvements

---

**Version**: 1.0.0  
**Last Updated**: 2025-01-19  
**Status**: Production Ready âœ…


